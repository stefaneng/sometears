% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/dagma.R, R/dagma_optim.R
\name{dagma_fit_linear}
\alias{dagma_fit_linear}
\alias{dagma_fit_linear_optim}
\title{DAGMA algorithm to learn DAGs}
\usage{
dagma_fit_linear(
  X,
  loss = torch_l2_cov,
  h_func = torch_h_logdet,
  s = 1.1,
  mu = c(10, 1, 0.1, 0.01, 0),
  epoch = 5,
  l1_beta = 0.05,
  lr = 1,
  trace = FALSE
)

dagma_fit_linear_optim(
  X,
  loss = l2_cov,
  h_func = h_logdet,
  s = 1.1,
  mu = c(1, 0.1, 0.01),
  l1_beta = 1e-04,
  trace = FALSE
)
}
\arguments{
\item{X}{A matrix of data in which each of the columns is a variable of interest in a directed acyclic graph}

\item{loss}{A loss function to use. Default is L2 loss.}

\item{h_func}{The continuous acyclic function to use. Default is h_logdet.}

\item{s}{A regularization parameter. Should be larger than the spectral radius of X.}

\item{mu}{A vector of weights to put on the loss function.}

\item{epoch}{ADAM optimizer epochs.}

\item{l1_beta}{L1 regularization parameter.}

\item{lr}{Learning rate for ADAM optimizer.}

\item{trace}{Boolean to enable progress printing}

\item{tol}{Tolerance for convergence.}

\item{betas}{Beta parameters for ADAM optimizer.}

\item{eps}{Epsilon parameter for ADAM optimizer.}
}
\value{
A matrix of the estimated W matrix
}
\description{
Implements the DAGMA algorithm to learn DAGs from Bello et al. (2023).
}
\examples{

B <- matrix(
c(0, 3, 0, 3,
 0, 0, 3, 0,
 0, 0, 0, 3,
 0, 0, 0, 0),
nrow = 4, ncol = 4, byrow = TRUE)
# Simulate from the DAG
d <- ncol(B)
X <- sim_linear_sem(B, n = 500, Sigma = 1 * diag(ncol(B)))

print(threshold_W(dagma_fit_linear(X, mu = c(10, 1, 0.1, 0.01, 0.001), l1_beta = 0.05), 0.1))
}
